{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seongha/anaconda3/envs/MGSSL/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n",
    "import torchvision\n",
    "from voc import *\n",
    "from coco import *\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet152, resnet101, resnet18, resnet34, resnet50\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from config import seed_everything\n",
    "seed_everything(0)\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "from PIL import Image\n",
    "import json\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82081 {'file_name': 'COCO_train2014_000000057870.jpg', 'labels': [12, 77, 51, 22, 27]}\n",
      "34\n",
      "Counter({1: 1234, 2: 407, 3: 116, 4: 27, 5: 8, 8: 3, 7: 2, 6: 1})\n",
      "45174.0 128.0\n",
      "dict_keys([49, 22, 18, 27, 26, 13, 14, 36, 74, 2, 8, 12, 21, 57, 75, 24, 23, 41, 51, 28, 62, 72, 20, 16, 76, 68, 7, 32, 77, 58, 61, 42, 73, 44, 67, 65, 70, 9, 0, 10, 59, 50, 53, 11, 17, 37, 47, 5, 4, 34, 78, 52, 54, 64, 40, 3, 30, 33, 66, 39, 25, 15, 79, 45, 46, 63, 31, 19, 1, 60, 56, 43, 29, 38, 71, 55, 6, 48, 69, 35]) dict_values([45174, 8950, 8606, 8378, 6518, 5968, 5028, 4861, 4321, 3924, 3844, 3734, 3322, 3291, 3191, 3170, 3159, 3097, 3084, 3041, 2986, 2893, 2818, 2791, 2749, 2667, 2539, 2537, 2530, 2511, 2493, 2475, 2464, 2442, 2368, 2343, 2317, 2287, 2243, 2241, 2209, 2202, 2180, 2098, 2080, 2068, 2003, 1884, 1804, 1798, 1771, 1671, 1645, 1631, 1625, 1618, 1518, 1511, 1510, 1471, 1389, 1340, 1324, 1290, 1216, 1214, 1205, 1186, 1171, 1170, 1105, 1089, 1062, 821, 700, 673, 668, 481, 151, 128])\n"
     ]
    }
   ],
   "source": [
    "path_csv = '../data/coco'\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "class_num = defaultdict(int)\n",
    "with open(path_csv + '/data/train_anno.json') as f:\n",
    "  adj = np.zeros((80,80))\n",
    "  import json\n",
    "  train = json.load(f)\n",
    "  print(len(train), train[0])\n",
    "\n",
    "  li = []\n",
    "  gt_labels = np.zeros((len(train),80))\n",
    "  img_id2idx = dict()\n",
    "  idx2img_id = []\n",
    "  for i,each in enumerate(train):\n",
    "    li += each['labels']\n",
    "    gt_labels[i, each['labels']] = 1\n",
    "    for l in each['labels']:\n",
    "      class_num[l] += 1\n",
    "\n",
    "  nums = gt_labels.sum(axis=0)\n",
    "  adj = []\n",
    "  for i,col in enumerate(gt_labels.T):\n",
    "    if i in [34]:\n",
    "      print(i)\n",
    "      selected = gt_labels[np.isin(col, [1.0]), :]\n",
    "      nonzero_cnt = (selected != 0).sum(1)\n",
    "      cnter = Counter(nonzero_cnt)\n",
    "      print(cnter)\n",
    "    cond_prob = gt_labels[np.isin(col,[1.0]),:].sum(axis=0)\n",
    "    cond_prob[i] = 0\n",
    "    adj.append(cond_prob)\n",
    "    # print(adj[-1])\n",
    "  nums = nums.tolist()\n",
    "  nums.sort()\n",
    "  nums.reverse()\n",
    "  # nums = reversed(nums)\n",
    "  print(max(nums), min(nums))\n",
    "  di={'adj': np.asarray(adj), \"nums\": np.asarray(nums)}\n",
    "  class_di = {k: v for k, v in sorted(class_num.items(), key=lambda item: item[1], reverse=True)} #sorted\n",
    "print(class_di.keys(), class_di.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dataset] Done!\n",
      "[annotation] Done!\n",
      "[json] Done!\n"
     ]
    }
   ],
   "source": [
    "test_dataset = COCO2014('../data/coco', phase='val', inp_name='../data/coco/coco_glove_word2vec.pkl')\n",
    "# train_dataset = Voc2007Classification('data/voc', 'trainval', inp_name='data/voc/voc_glove_word2vec.pkl', LT=True)\n",
    "# test_dataset = Voc2007Classification('data/voc', 'test', inp_name='data/voc/voc_glove_word2vec.pkl')\n",
    "# train_dataset = COCO2014('data/coco', phase='train', inp_name='data/coco/coco_glove_word2vec.pkl')\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                  std=[0.229, 0.224, 0.225])\n",
    "test_dataset.transform = transforms.Compose([\n",
    "                MultiScaleCrop(224, scales=(1.0, 0.875, 0.75, 0.66, 0.5), max_distort=2),\n",
    "                transforms.ToTensor(),\n",
    "                normalize,\n",
    "            ])\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "from util import AveragePrecisionMeter\n",
    "AP = AveragePrecisionMeter(difficult_examples=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'resnet50': 'resnetv2_50x3_bitm_in21k', 'vit': 'vit_base_patch16_224_in21k', 'vit-hybrid': 'vit_base_r50_s16_224_in21k', 'swin': 'swin_base_patch4_window7_224_in22k', 'convnext': 'convnext_base_in22k', 'mlpmixer': 'mixer_b16_224_in21k'}\n",
      "resnet50 : resnetv2_50x3_bitm_in21k\n",
      "vit : vit_base_patch16_224_in21k\n",
      "vit-hybrid : vit_base_r50_s16_224_in21k\n",
      "swin : swin_base_patch4_window7_224_in22k\n",
      "convnext : convnext_base_in22k\n",
      "mlpmixer : mixer_b16_224_in21k\n",
      "Linear(in_features=768, out_features=80, bias=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seongha/anaconda3/envs/MGSSL/lib/python3.9/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646756402876/work/aten/src/ATen/native/TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "from models import *\n",
    "from backbones.config import config\n",
    "import pathlib\n",
    "\n",
    "print(config)\n",
    "for k, v in config.items():\n",
    "  print(\"{} : {}\".format(k, v))\n",
    "  pathlib.Path('../figures/{}'.format(k)).mkdir(parents=True, exist_ok=True) \n",
    "\n",
    "m_li = [base_resnet50(model_path=config['resnet50'], num_classes=80, pretrained=True),\\\n",
    "   base_vit(config['vit'], 80, image_size=224, pretrained=True),\\\n",
    "      base_swin(config['swin'], 80, image_size=224, pretrained=True, requires_grad=True),\\\n",
    "         base_convnext(config['convnext'], 80, image_size=224, pretrained=True), \\\n",
    "           base_mlpmixer(config['mlpmixer'], num_classes=80, image_size=224, pretrained=True)]\n",
    "# m_li2 = [BaseResnet(m_li[0], 80)]\n",
    "p_li = ['/home/seongha/LT-ML/checkpoint/coco/coco_LT(0)_label_cnt_in21k-4-4-0_resnet50_base_best.pth.tar', \\\n",
    "  '/home/seongha/LT-ML/checkpoint/coco/coco_LT(0)_label_cnt_in21k-4-4-0_vit_base_best.pth.tar', \\\n",
    "    '/home/seongha/LT-ML/checkpoint/coco/coco_LT(0)_label_cnt_in22k-4-4-0_swin_base_best.pth.tar',\\\n",
    "  '/home/seongha/LT-ML/checkpoint/coco/coco_LT(0)_label_cnt_in22k-4-4-0_convnext_base_best.pth.tar',\\\n",
    "      '/home/seongha/LT-ML/checkpoint/coco/coco_LT(0)_label_cnt_in21k-4-4-0_mlpmixer_base_best.pth.tar' ,\\\n",
    "  ]\n",
    "\n",
    "def get_model(index):\n",
    "  path = p_li[index]\n",
    "  model = m_li[index]\n",
    "  di = torch.load(path)\n",
    "  print(di['best_score'])\n",
    "  print(di.keys())\n",
    "  model.load_state_dict(di['state_dict'])\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vit\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "key_list = list(config)\n",
    "print(key_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mAP': tensor(29.3734), 'OF1': 0.35194173201084833, 'CF1': 0.15985432026494287}\n",
      "dict_keys(['epoch', 'arch', 'state_dict', 'best_score'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [2:03:36, 47.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40137, 80])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = get_model(i).to(device)\n",
    "model = model.eval()\n",
    "for i, (input, target) in tqdm(enumerate(test_loader)):\n",
    "  img, path, inp = input\n",
    "  target[target == 0] = 1\n",
    "  target[target == -1] = 0\n",
    "  feat_Var = torch.autograd.Variable(img).float().to(device)\n",
    "  \n",
    "  # output = model(feat_Var, None).detach()\n",
    "  output = model(feat_Var, None).detach()\n",
    "  # print(output.requires_grad, target.requires_grad)\n",
    "  # print(output.shape, target.shape)\n",
    "  AP.add(output, target)\n",
    "\n",
    "# map = 100 * AP.value().mean()\n",
    "# print(100 * AP.value())\n",
    "# ap_li = 100 * AP.value()\n",
    "print(AP.scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50 : resnetv2_50x3_bitm_in21k\n",
      "vit : vit_base_patch16_224_in21k\n",
      "vit-hybrid : vit_base_r50_s16_224_in21k\n",
      "swin : swin_base_patch4_window7_224_in22k\n",
      "convnext : convnext_base_in22k\n",
      "mlpmixer : mixer_b16_224_in21k\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "for k, v in config.items():\n",
    "  print(\"{} : {}\".format(k, v))\n",
    "  pathlib.Path('../figures/{}'.format(k)).mkdir(parents=True, exist_ok=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([840])\n",
      "torch.Size([491])\n",
      "torch.Size([1832])\n",
      "torch.Size([728])\n",
      "torch.Size([799])\n",
      "torch.Size([845])\n",
      "torch.Size([341])\n",
      "torch.Size([1292])\n",
      "torch.Size([1961])\n",
      "torch.Size([1114])\n",
      "torch.Size([1121])\n",
      "torch.Size([1048])\n",
      "torch.Size([1828])\n",
      "torch.Size([2912])\n"
     ]
    }
   ],
   "source": [
    "classwise_img = dict({\"class_index\":[], \"1\":[], \"2\":[], \"3\":[], \"-1\":[], \"-2\":[], \"-3\":[]})\n",
    "for i in range(AP.scores.shape[1]):\n",
    "  score = AP.scores[:,i]\n",
    "  target = AP.targets[:, i]\n",
    "  score_true = score[torch.where(target == 1)]\n",
    "  # print(torch.where(target==1))\n",
    "  \n",
    "  dataset_true = [test_dataset[each] for each in torch.where(target == 1)[0].tolist()]\n",
    "  sorted, indices = torch.sort(score_true, dim=0, descending=True)\n",
    "  \n",
    "  print(score_true.shape)\n",
    "  classwise_img[\"class_index\"].append(i)\n",
    "  classwise_img[\"1\"].append(dataset_true[int(indices[0])][0][1])\n",
    "  classwise_img[\"2\"].append(dataset_true[int(indices[1])][0][1])\n",
    "  classwise_img[\"3\"].append(dataset_true[int(indices[2])][0][1])\n",
    "  classwise_img[\"-1\"].append(dataset_true[int(indices[-1])][0][1])\n",
    "  classwise_img[\"-2\"].append(dataset_true[int(indices[-2])][0][1])\n",
    "  classwise_img[\"-3\"].append(dataset_true[int(indices[-3])][0][1])\n",
    "  \n",
    "classwise_img\n",
    "img_df = pd.DataFrame(data=classwise_img)\n",
    "img_df.to_csv(\"../figures/{}/topandworst.csv\".format(key_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_51055/868710965.py:3: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig = plt.figure(figsize=(12, 18))\n"
     ]
    }
   ],
   "source": [
    "plt.rcParams.update({'font.size': 8})\n",
    "for i, row in img_df.iterrows():\n",
    "  fig = plt.figure(figsize=(12, 12))\n",
    "  for idx, (j, item) in enumerate(row.iteritems()):\n",
    "    if j == \"class_index\":\n",
    "      continue\n",
    "    a = fig.add_subplot(2, 3, idx)\n",
    "    img_id = '/home/seongha/LT-ML/data/coco/data/val2014/{}'.format(item)\n",
    "    image = Image.open(img_id)  \n",
    "    imgplot = plt.imshow(image)\n",
    "    # a.axis(\"off\")\n",
    "    # a.set_title(names[i].split('(')[0], fontsize=30)\n",
    "  \n",
    "  plt.savefig('../figures/{}/topandworst_class_{}.png'.format(key_list[i], i), bbox_inches='tight', dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classwise AP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_li = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat',\n",
    "       'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person',\n",
    "       'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']#voc\n",
    "label_li = list(class_di.keys()) #coco\n",
    "ap_li = 100 * AP.value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#classifier\n",
    "ap_li = [75.4188, 76.3768, 66.3551, 79.1177, 45.1441, 62.4649, 83.6811, 85.9619,\n",
    "        58.1541, 48.6313, 67.8912, 79.3836, 79.2103, 69.3254, 88.5846, 50.0462,\n",
    "        26.8350, 57.0530, 75.6681, 71.1823]#FC\n",
    "ap_li2 = [77.9105, 76.8534, 71.2095, 80.9140, 45.2674, 63.6200, 84.0961, 86.4019,\n",
    "        59.8740, 52.9656, 68.0257, 80.5327, 79.3948, 71.0906, 88.7570, 49.5162,\n",
    "        33.0532, 55.2915, 76.8210, 70.2609]#Transformer\n",
    "ap_li_gcn = [44.9041, 51.7194, 41.8896, 52.5085, 31.0836, 42.8794, 75.6171, 61.9646,\n",
    "        39.8540, 26.9209, 45.8847, 50.5602, 48.6032, 48.8849, 78.4147, 37.8425,\n",
    "        15.7030, 46.4849, 45.6828, 53.3943]#gcn\n",
    "ap_li_tc = [52.6595, 59.2412, 48.0880, 60.5390, 34.5672, 49.0508, 77.6743, 70.0045,\n",
    "        42.0592, 32.3638, 49.0484, 57.0762, 55.9363, 55.3863, 81.9262, 41.5481,\n",
    "        18.1342, 48.6349, 52.5640, 58.6664]#TC\n",
    "\n",
    "#backbone;\n",
    "ap_li_resnet50_fc_coco = [44.8806, 18.7181,  4.2505, 26.0276,  1.8891,  2.0793, 55.0725, 29.3584,\n",
    "        21.6527, 13.7635, 34.6959, 50.7117,  4.5387,  9.8258, 10.3550, 42.5709,\n",
    "        39.2878, 19.0187, 29.4253, 10.1510, 57.6950, 11.8762, 13.9065, 42.1499,\n",
    "         4.6982, 33.9326, 10.8716, 15.9627, 32.3844, 19.4244, 61.4208, 29.5272,\n",
    "         3.1157,  3.6808, 75.4917,  0.1942,  5.2710, 19.7860, 15.4992, 16.0211,\n",
    "        15.0432,  3.9782, 21.1419,  8.8907, 30.8293,  1.9951, 32.1277, 21.3268,\n",
    "        20.2985, 83.6436, 46.0174,  5.8537, 20.1276,  5.9066, 20.2521, 12.6364,\n",
    "        54.7259, 21.3757,  3.1344,  6.6266,  3.5166,  3.2945,  3.5212, 31.7686,\n",
    "        15.5602, 11.4469, 40.4510,  2.9287, 17.3079,  0.1819, 36.1461,  2.6347,\n",
    "        30.3691, 31.7924, 28.6856, 21.0613, 17.1495, 20.7845,  3.5991, 73.5261]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_class_size(ap_li):\n",
    "  Sorted_Ap = []\n",
    "  for k, v in class_di.items():\n",
    "        idx = label_li.index(k)\n",
    "        print(\"{}, {}, {}\".format(k, v, ap_li[idx]))\n",
    "        Sorted_Ap.append( ap_li[idx])\n",
    "\n",
    "  return Sorted_Ap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sorted class wise ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap_li = [(87.2317), (37.9691), (25.5833), (60.2952), (71.5306), (82.1195), (88.1945), (65.4069), (40.6149), (41.1147), (56.1550), (70.4887), (47.4118), (46.0852), (51.6309), (80.2644), (71.3544), (53.0769), (62.6369), (46.5251), (83.0326), (38.1768), (54.7562), (64.7367), (53.6059), (62.9250), (50.5712), (65.0720), (66.4795), (56.4693), (93.2486), (53.6870), (45.0067), (49.6613), (94.2364), (2.5078), (32.1601), (71.6280), (53.7966), (66.5539), (73.0900), (37.8341), (65.7573), (42.9252), (76.6879), (66.2664), (53.7973), (64.0184), (44.7371), (95.6273), (79.7539), (32.5730), (52.1021), (43.1948), (54.0491), (29.8070), (76.0650), (72.6686), (66.8284), (83.8258), (51.1537), (37.7894), (58.2430), (50.6816), (39.5533), (83.3577), (63.9864), (90.7062), (63.3839), (8.1543), (83.6346), (31.7384), (60.2249), (87.2840), (52.6824), (64.5797), (57.4210), (57.0662), (40.5110), (95.1418)]#resnet50\n",
    "\n",
    "ap_li = [(45.3500), (18.2222), (13.6026), (23.4529), (42.3237), (49.2937), (22.8450), (20.3572), (15.8094), (14.2007), (14.6072), (27.6725), (19.2367), (23.4214), (28.1970), (49.6993), (35.2519), (13.4251), (39.2461), (25.9420), (25.2125), (14.7421), (30.5735), (27.2955), (15.7352), (13.5201), (27.8317), (40.5388), (10.5245), (13.2751), (37.1561), (7.5296), (24.1639), (19.6291), (54.0519), (0.7407), (17.6404), (13.3025), (11.5703), (24.3879), (34.7420), (19.7303), (27.4391), (16.8291), (38.1872), (25.5800), (30.7358), (24.3021), (3.6065), (84.7080), (46.3175), (18.6291), (19.6434), (14.5465), (21.8009), (3.2022), (25.4228), (42.3088), (15.8355), (59.7384), (23.9780), (16.0761), (36.3887), (28.1691), (7.4630), (52.5339), (13.9503), (54.7527), (24.7485), (1.0721), (46.4781), (5.2758), (30.5740), (40.9817), (26.0356), (31.9627), (14.5073), (20.7029), (12.1453), (82.5090)]#vit\n",
    "ap_li = [(91.8544), (43.1256), (26.5690), (70.0659), (76.5766), (84.6905), (90.6705), (69.3488), (47.3465), (46.3260), (54.2423), (69.1731), (47.7069), (46.4438), (52.9935), (83.0113), (75.7541), (61.6797), (63.1336), (45.6008), (87.5212), (46.0696), (54.7016), (67.6697), (61.8478), (74.0051), (49.7442), (65.4748), (67.8092), (59.1135), (95.4002), (56.4176), (42.4934), (57.2041), (95.3415), (3.8831), (33.3568), (81.3636), (60.9955), (66.7404), (79.6752), (40.4530), (75.0224), (44.1766), (80.7608), (68.4051), (61.7054), (69.1169), (47.6977), (95.0259), (87.2624), (32.2685), (63.9545), (60.0900), (57.4585), (30.5509), (81.0403), (77.1382), (79.4230), (79.7268), (52.0464), (37.4560), (52.7913), (45.6313), (47.3443), (87.6463), (72.8188), (95.4763), (67.9169), (4.8832), (87.2957), (29.0972), (64.6534), (91.6069), (50.3383), (70.0396), (65.2082), (60.7164), (47.2639), (96.1118)]#swin\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>class_index</th>\n",
       "      <th>class_size</th>\n",
       "      <th>AP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>45174</td>\n",
       "      <td>91.8544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>8950</td>\n",
       "      <td>43.1256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>8606</td>\n",
       "      <td>26.5690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>8378</td>\n",
       "      <td>70.0659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>6518</td>\n",
       "      <td>76.5766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75</td>\n",
       "      <td>55</td>\n",
       "      <td>673</td>\n",
       "      <td>70.0396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76</td>\n",
       "      <td>6</td>\n",
       "      <td>668</td>\n",
       "      <td>65.2082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>48</td>\n",
       "      <td>481</td>\n",
       "      <td>60.7164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>78</td>\n",
       "      <td>69</td>\n",
       "      <td>151</td>\n",
       "      <td>47.2639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>79</td>\n",
       "      <td>35</td>\n",
       "      <td>128</td>\n",
       "      <td>96.1118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  class_index  class_size       AP\n",
       "0       0           49       45174  91.8544\n",
       "1       1           22        8950  43.1256\n",
       "2       2           18        8606  26.5690\n",
       "3       3           27        8378  70.0659\n",
       "4       4           26        6518  76.5766\n",
       "..    ...          ...         ...      ...\n",
       "75     75           55         673  70.0396\n",
       "76     76            6         668  65.2082\n",
       "77     77           48         481  60.7164\n",
       "78     78           69         151  47.2639\n",
       "79     79           35         128  96.1118\n",
       "\n",
       "[80 rows x 4 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ = {\"class_index\": list(class_di.keys()),\n",
    "\"class_size\": list(class_di.values()),\n",
    "\"AP\": ap_li}\n",
    "\n",
    "df = pd.DataFrame(data=data_)\n",
    "df.to_csv(\"sorted_ap_{}.csv\".format(key_list[i]))\n",
    "df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### label distribution csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    class_index  class_size       AP\n",
      "79           35         128  96.1118\n",
      "67           19        1186  95.4763\n",
      "30           61        2493  95.4002\n",
      "34           67        2368  95.3415\n",
      "49           34        1798  95.0259\n",
      "0            49       45174  91.8544\n",
      "73           38         821  91.6069\n",
      "6            14        5028  90.6705\n",
      "35\n",
      "Counter({3: 42, 4: 27, 5: 22, 2: 17, 6: 10, 7: 3, 8: 3, 1: 3, 10: 1})\n",
      "19\n",
      "Counter({3: 290, 4: 239, 2: 210, 5: 160, 6: 88, 7: 67, 1: 36, 8: 31, 9: 28, 11: 14, 10: 12, 12: 9, 13: 1, 14: 1})\n",
      "61\n",
      "Counter({6: 395, 7: 375, 5: 352, 4: 346, 8: 267, 3: 219, 9: 179, 10: 110, 2: 85, 11: 81, 12: 45, 13: 20, 14: 8, 15: 5, 1: 4, 16: 2})\n",
      "67\n",
      "Counter({3: 1083, 2: 688, 4: 388, 5: 146, 6: 44, 7: 9, 1: 4, 9: 3, 8: 2, 11: 1})\n",
      "34\n",
      "Counter({1: 1234, 2: 407, 3: 116, 4: 27, 5: 8, 8: 3, 7: 2, 6: 1})\n",
      "49\n",
      "Counter({2: 15997, 3: 12123, 4: 7145, 5: 4298, 6: 2350, 7: 1388, 8: 747, 9: 436, 1: 238, 10: 228, 11: 124, 12: 57, 13: 27, 14: 9, 15: 6, 16: 1})\n",
      "38\n",
      "Counter({2: 209, 3: 181, 4: 126, 1: 81, 5: 75, 6: 66, 7: 38, 8: 19, 9: 13, 10: 6, 11: 5, 12: 1, 13: 1})\n",
      "14\n",
      "Counter({4: 853, 5: 731, 6: 690, 3: 680, 7: 596, 8: 404, 2: 350, 9: 311, 10: 180, 11: 115, 12: 57, 13: 28, 1: 15, 14: 9, 15: 6, 16: 2, 18: 1})\n",
      "65\n",
      "Counter({2: 1782, 3: 362, 4: 103, 5: 42, 1: 29, 6: 15, 7: 5, 8: 3, 10: 2})\n",
      "60\n",
      "Counter({2: 711, 3: 345, 4: 83, 5: 17, 1: 9, 6: 3, 7: 2})\n",
      "18\n",
      "Counter({3: 2552, 4: 2111, 5: 1385, 2: 1334, 6: 626, 7: 278, 8: 129, 1: 97, 9: 51, 10: 25, 11: 12, 12: 3, 13: 2, 14: 1})\n",
      "43\n",
      "Counter({5: 139, 6: 137, 4: 137, 7: 130, 3: 125, 8: 102, 9: 82, 2: 75, 1: 46, 10: 44, 11: 30, 12: 21, 13: 11, 14: 4, 15: 3, 16: 2, 18: 1})\n",
      "3\n",
      "Counter({2: 402, 3: 337, 4: 257, 1: 204, 5: 140, 6: 94, 7: 63, 8: 46, 9: 26, 10: 22, 11: 11, 12: 9, 13: 3, 14: 2, 16: 1, 15: 1})\n",
      "52\n",
      "Counter({3: 250, 5: 215, 4: 207, 6: 183, 2: 176, 7: 164, 8: 144, 9: 107, 1: 82, 10: 59, 11: 38, 12: 22, 13: 11, 14: 6, 15: 4, 16: 2, 18: 1})\n",
      "70\n",
      "Counter({2: 859, 1: 728, 3: 406, 4: 196, 5: 90, 6: 25, 7: 9, 11: 2, 10: 1, 8: 1})\n",
      "15\n",
      "Counter({3: 294, 2: 294, 1: 216, 4: 195, 5: 143, 6: 74, 7: 50, 8: 24, 9: 18, 10: 17, 11: 7, 12: 6, 13: 2})\n"
     ]
    }
   ],
   "source": [
    "top = df.nlargest(8, 'AP')\n",
    "print(top)\n",
    "data_ = []\n",
    "for i, j in zip(top.class_index, top.index):\n",
    "  print(i)\n",
    "  col = gt_labels[:, i]\n",
    "  selected = gt_labels[np.isin(col, [1.0]), :]\n",
    "  nonzero_cnt = (selected != 0).sum(1)\n",
    "  cnter = Counter(nonzero_cnt)\n",
    "  print(cnter)\n",
    "  cnter = dict(sorted(cnter.items(),key = lambda i: i[0]))\n",
    "  cnter['class_index'] = i\n",
    "  cnter['rank'] = j\n",
    "  data_.append(cnter)\n",
    "df_top5 = pd.DataFrame(data=data_)\n",
    "df_top5 = df_top5.fillna(0)\n",
    "df_top5 = df_top5.set_index(['class_index', 'rank'])\n",
    "df_top5.to_csv(\"label_distribution_top_{}.csv\".format(name_map[idx]))\n",
    "\n",
    "worst = df.nsmallest(8, 'AP')\n",
    "data_ = []\n",
    "for i, j in zip(worst.class_index, worst.index):\n",
    "  print(i)\n",
    "  col = gt_labels[:, i]\n",
    "  selected = gt_labels[np.isin(col, [1.0]), :]\n",
    "  nonzero_cnt = (selected != 0).sum(1)\n",
    "  cnter = Counter(nonzero_cnt)\n",
    "  print(cnter)\n",
    "  cnter = dict(sorted(cnter.items(),key = lambda i: i[0]))\n",
    "  cnter['class_index'] = i\n",
    "  cnter['rank'] = j\n",
    "  data_.append(cnter)\n",
    "df_worst5 = pd.DataFrame(data=data_)\n",
    "df_worst5 = df_worst5.fillna(0)\n",
    "df_worst5 = df_worst5.set_index(['class_index', 'rank'])\n",
    "df_worst5.to_csv(\"label_distribution_worst_{}.csv\".format(name_map[idx]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "765b26ec2fc4c2066cf7ce8a0dde5a8255de29dd3973b3be957926608459ba30"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('MGSSL': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
