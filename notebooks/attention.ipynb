{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import torchvision\n",
    "from voc import *\n",
    "from coco import *\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet152, resnet101, resnet18, resnet34, resnet50\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from config import seed_everything\n",
    "seed_everything(0)\n",
    "import timm\n",
    "\n",
    "# from models import *\n",
    "from backbones.config import config\n",
    "import pathlib\n",
    "from torch import nn, einsum\n",
    "from einops import rearrange, repeat\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model(config[\"swin\"], num_classes=80, pretrained=True).to(device)\n",
    "pre = torch.nn.Sequential(*[model.patch_embed,\n",
    "model.pos_drop])\n",
    "\n",
    "print(len(model.layers))\n",
    "post = torch.nn.Sequential(*[model.norm,\n",
    "# model.fc_norm,\n",
    "model.head])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.randn(1, 3, 384, 384).to(device)\n",
    "\n",
    "ln = nn.LayerNorm(1024).to(device)\n",
    "def forward_(model, inp):\n",
    "  inp = pre(inp)\n",
    "  print(inp.shape)\n",
    "\n",
    "  int_li = []\n",
    "  for b in model.layers:\n",
    "    inp = b(inp)\n",
    "    print(inp.shape)\n",
    "    int_li.append(inp)\n",
    "\n",
    "  inp = ln(inp)\n",
    "  print(inp.shape)\n",
    "  inp = post(inp)\n",
    "  print(inp.shape)\n",
    "  return inp, int_li\n",
    "\n",
    "inp, int_li = forward_(model, inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll1 = nn.Linear(2304, 1, bias=False).to(device)\n",
    "ll2 = nn.Linear(576, 1, bias=False).to(device)\n",
    "ll3 = nn.Linear(144, 1, bias=False).to(device)\n",
    "ll4 = nn.Linear(144, 1, bias=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kv(int_li):\n",
    "  res = None\n",
    "  softmax = nn.Softmax(dim=1)\n",
    "  val, ind = softmax(ll1(int_li[0].mT)).sort(dim=1, descending=True)\n",
    "  top4 = ind[:,0:4,].flatten()\n",
    "  print(top4)\n",
    "  print(int_li[0][:,:,top4].shape)\n",
    "  res = int_li[0][:,:,top4]\n",
    "\n",
    "  val, ind = softmax(ll2(int_li[1].mT)).sort(dim=1, descending=True)\n",
    "  top4 = ind[:,0:4,].flatten()\n",
    "  print(top4)\n",
    "  print(int_li[1][:,:,top4].shape)\n",
    "  res = torch.cat((res, int_li[1][:,:,top4]), dim=1)\n",
    "\n",
    "  val, ind = softmax(ll3(int_li[2].mT)).sort(dim=1, descending=True)\n",
    "  top4 = ind[:,0:4,].flatten()\n",
    "  print(top4)\n",
    "  print(int_li[2][:,:,top4].shape)\n",
    "  res = torch.cat((res, int_li[2][:,:,top4]), dim=1)\n",
    "\n",
    "  val, ind = softmax(ll4(int_li[3].mT)).sort(dim=1, descending=True)\n",
    "  top4 = ind[:,0:4,].flatten()\n",
    "  print(top4)\n",
    "  print(int_li[3][:,:,top4].shape)\n",
    "  res = torch.cat((res, int_li[3][:,:,top4]), dim=1)\n",
    "\n",
    "  return res\n",
    "\n",
    "get_kv(int_li).shape\n",
    "# ll2 = nn.Linear(512, 1, bias=False).to(device)\n",
    "# softmax = nn.Softmax(dim=1)\n",
    "# val, ind = softmax(ll2(int_li[1])).sort(dim=1, descending=True)\n",
    "# ind[0,0:4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 3168\n",
    "inner_dim = 3168//1\n",
    "group_queries = True\n",
    "group_key_values = True\n",
    "offset_groups = 1\n",
    "heads=1\n",
    "to_q = nn.Conv1d(144, inner_dim, 1, groups = offset_groups if group_queries else 1, bias = False).to(device)\n",
    "to_k = nn.Conv1d(dim, inner_dim, 1, groups = offset_groups if group_key_values else 1, bias = False).to(device)\n",
    "to_v = nn.Conv1d(dim, inner_dim, 1, groups = offset_groups if group_key_values else 1, bias = False).to(device)\n",
    "to_out = nn.Conv1d(inner_dim, 144, 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "group = lambda t: rearrange(t, 'b (g d) n -> (b g) d n', g = offset_groups)\n",
    "grouped_queries = group(q)\n",
    "grouped_queries.shape #torch.Size([4, 49, 768])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention( out, int_li):\n",
    "  kv = get_kv(int_li)\n",
    "  k, v = to_k(kv), to_v(kv)\n",
    "  # k.shape, v.shape #(torch.Size([1, 196, 768]), torch.Size([1, 196, 768]))\n",
    "  q = to_q(out)\n",
    "  # q.shape #torch.Size([1, 196, 768])\n",
    "\n",
    "  # split out heads\n",
    "  q, k, v = map(lambda t: rearrange(t, 'b (h d) n -> b h n d', h = heads), (q, k, v))\n",
    "\n",
    "  # query / key similarity\n",
    "  sim = einsum('b h i d, b h j d -> b h i j', q, k)\n",
    "  # numerical stability\n",
    "\n",
    "  sim = sim - sim.amax(dim = -1, keepdim = True).detach()\n",
    "\n",
    "  # attention\n",
    "  dropout = nn.Dropout(0.0)\n",
    "  attn = sim.softmax(dim = -1)\n",
    "  attn = dropout(attn)\n",
    "  attn.shape\n",
    "\n",
    "  # aggregate and combine heads\n",
    "\n",
    "  out = einsum('b h i j, b h j d -> b h i d', attn, v)\n",
    "  out = rearrange(out, 'b h n d -> b (h d) n')\n",
    "  out = to_out(out)\n",
    "  print(out.shape)\n",
    "  return out\n",
    "attention(int_li[3], int_li)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = COCO2017('../data/coco', phase='train')\n",
    "# partial=torch.utils.data.Subset(test_dataset, list(range(100)))\n",
    "# train_dataset = Voc2007Classification('data/voc', 'trainval', inp_name='data/voc/voc_glove_word2vec.pkl', LT=True)\n",
    "# test_dataset = Voc2007Classification('data/voc', 'test', inp_name='data/voc/voc_glove_word2vec.pkl')\n",
    "# train_dataset = COCO2014('data/coco', phase='train', inp_name='data/coco/coco_glove_word2vec.pkl')\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                  std=[0.229, 0.224, 0.225])\n",
    "train_dataset.transform = transforms.Compose([\n",
    "                Warp(384),\n",
    "                transforms.ToTensor(),\n",
    "                normalize,\n",
    "            ])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=50, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MultiLabelSoftMarginLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model = get_model(i).to(device)\n",
    "model = model.train()\n",
    "act_li = np.array([[]])\n",
    "for i, (input, target) in tqdm(enumerate(train_loader)):\n",
    "  img, path = input\n",
    "  target[target == 0] = 1\n",
    "  target[target == -1] = 0\n",
    "  feat_Var = torch.autograd.Variable(img).float().to(device)\n",
    "  \n",
    "  # output = model(feat_Var, None).detach()\n",
    "  # output = model(feat_Var)\n",
    "  output, int_li = forward_(model, feat_Var)\n",
    "  \n",
    "  out = attention(output, int_li)\n",
    "  out = out.mean(dim=1)\n",
    "  criterion(out, target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "60887706f19020ebdc58f2aefdb30076f5f51d5973d281c7596168e0afd68511"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('LTML': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
