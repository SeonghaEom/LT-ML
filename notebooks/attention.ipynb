{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import torchvision\n",
    "from voc import *\n",
    "from coco import *\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet152, resnet101, resnet18, resnet34, resnet50\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from config import seed_everything\n",
    "seed_everything(0)\n",
    "import timm\n",
    "\n",
    "# from models import *\n",
    "from backbones.config import config\n",
    "import pathlib\n",
    "from torch import nn, einsum\n",
    "from einops import rearrange, repeat\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/torch/cuda/__init__.py:146: UserWarning: \n",
      "NVIDIA RTX A5000 with CUDA capability sm_86 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n",
      "If you want to use the NVIDIA RTX A5000 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    }
   ],
   "source": [
    "model = timm.create_model(config[\"vit\"], num_classes=80, pretrained=True).to(device)\n",
    "pre = torch.nn.Sequential(*[model.patch_embed,\n",
    "model.pos_drop])\n",
    "\n",
    "print(len(model.blocks))\n",
    "post = torch.nn.Sequential(*[model.norm,\n",
    "model.fc_norm,\n",
    "model.head])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 196, 768])\n",
      "torch.Size([1, 196, 768])\n",
      "torch.Size([1, 196, 768])\n",
      "torch.Size([1, 196, 768])\n",
      "torch.Size([1, 196, 768])\n",
      "torch.Size([1, 196, 768])\n",
      "torch.Size([1, 196, 768])\n",
      "torch.Size([1, 196, 768])\n",
      "torch.Size([1, 196, 768])\n",
      "torch.Size([1, 196, 768])\n",
      "torch.Size([1, 196, 768])\n",
      "torch.Size([1, 196, 768])\n",
      "torch.Size([1, 196, 768])\n",
      "torch.Size([1, 196, 80])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.5977, -0.4091,  1.4682,  ..., -0.4644, -0.0036,  2.7809],\n",
       "          [ 1.4621, -1.0185,  0.6426,  ..., -0.2896, -1.1233,  1.8893],\n",
       "          [ 1.5859, -1.5175,  0.5555,  ..., -0.6128, -0.2043,  2.2052],\n",
       "          ...,\n",
       "          [ 3.1653,  1.1116, -1.0886,  ..., -0.0912, -1.4020,  1.6420],\n",
       "          [ 0.5902, -0.3702,  0.4086,  ..., -1.5330, -0.7562,  2.9862],\n",
       "          [ 1.2250, -1.4316,  0.7843,  ..., -1.5045, -0.4867,  2.2433]]],\n",
       "        grad_fn=<ViewBackward0>),\n",
       " [tensor([[[-1.0536,  0.0774, -0.7863,  ...,  0.5789, -0.1096,  1.9263],\n",
       "           [-1.1046,  0.0685, -0.7852,  ...,  0.3846,  0.4005,  1.8546],\n",
       "           [-1.1540, -0.1799, -0.7700,  ...,  0.4842,  0.0243,  1.8204],\n",
       "           ...,\n",
       "           [-0.6701,  0.1813, -0.7853,  ...,  0.1094,  0.0572,  2.0724],\n",
       "           [-1.2050, -0.2024, -0.8298,  ...,  0.2395, -0.0288,  1.1773],\n",
       "           [-0.9944, -0.0105, -0.9310,  ...,  0.0880,  0.0674,  1.9232]]],\n",
       "         grad_fn=<AddBackward0>),\n",
       "  tensor([[[-0.2571,  0.2323, -0.5009,  ..., -0.1416,  0.0656,  1.4181],\n",
       "           [-0.1643,  0.1056, -0.6051,  ..., -0.4248,  0.5440,  1.6393],\n",
       "           [-0.3333, -0.0950, -0.5690,  ..., -0.3542,  0.1215,  1.6084],\n",
       "           ...,\n",
       "           [ 0.1720,  0.2564, -0.5227,  ..., -0.7301,  0.0276,  1.6503],\n",
       "           [-0.4016, -0.1203, -0.6475,  ..., -0.7442,  0.3184,  0.9716],\n",
       "           [-0.1240,  0.0752, -0.6116,  ..., -0.5884,  0.0900,  1.6076]]],\n",
       "         grad_fn=<AddBackward0>),\n",
       "  tensor([[[-0.3557, -0.0970, -0.5856,  ..., -0.1278,  0.1708,  1.4244],\n",
       "           [-0.2621, -0.2794, -0.5794,  ..., -0.4362,  0.6895,  1.6110],\n",
       "           [-0.4667, -0.5918, -0.6734,  ..., -0.3452,  0.3210,  1.5502],\n",
       "           ...,\n",
       "           [-0.0560,  0.1981, -0.5717,  ..., -0.3810,  0.5192,  1.3858],\n",
       "           [-0.5323, -0.2364, -0.7301,  ..., -0.3136,  0.4228,  1.0740],\n",
       "           [-0.1661, -0.2826, -0.6751,  ..., -0.5997,  0.2023,  1.6019]]],\n",
       "         grad_fn=<AddBackward0>),\n",
       "  tensor([[[-0.1221, -0.2552, -0.6511,  ...,  0.3041,  0.1864,  1.2898],\n",
       "           [ 0.0867, -0.5481, -0.5692,  ..., -0.3889,  0.4046,  1.6390],\n",
       "           [-0.0482, -0.5641, -0.6158,  ..., -0.2418,  0.1020,  1.3217],\n",
       "           ...,\n",
       "           [-0.0797,  0.1881, -0.4449,  ..., -0.2623,  0.3814,  1.2874],\n",
       "           [-0.4723, -0.4391, -0.6663,  ..., -0.1754,  0.1831,  1.1243],\n",
       "           [ 0.1841, -0.3045, -0.6639,  ..., -0.3664,  0.3787,  1.4751]]],\n",
       "         grad_fn=<AddBackward0>),\n",
       "  tensor([[[-0.0762, -0.4824, -0.5209,  ...,  0.0819,  0.0971,  1.0394],\n",
       "           [ 0.2314, -0.6229, -0.4526,  ..., -0.5390,  0.2135,  1.5784],\n",
       "           [ 0.1516, -0.5735, -0.4378,  ..., -0.5444,  0.0682,  1.3974],\n",
       "           ...,\n",
       "           [ 0.0448, -0.0020, -0.3804,  ..., -0.4406,  0.1035,  1.2982],\n",
       "           [-0.2472, -0.4378, -0.5552,  ..., -0.5019,  0.1618,  1.2684],\n",
       "           [ 0.1224, -0.4225, -0.5421,  ..., -0.5696,  0.1825,  1.3612]]],\n",
       "         grad_fn=<AddBackward0>),\n",
       "  tensor([[[-0.3695, -0.3475, -0.1462,  ..., -0.1941, -0.1843,  0.5092],\n",
       "           [-0.1398, -0.4051, -0.0222,  ..., -0.8043, -0.1212,  1.1386],\n",
       "           [-0.0999, -0.4756, -0.0878,  ..., -0.7659, -0.1861,  0.6107],\n",
       "           ...,\n",
       "           [-0.3527,  0.1270,  0.0562,  ..., -0.5978, -0.0720,  0.7695],\n",
       "           [-0.4652, -0.3740, -0.2989,  ..., -0.7825, -0.2882,  0.8199],\n",
       "           [-0.0802, -0.4546, -0.1803,  ..., -0.5816, -0.1435,  0.9775]]],\n",
       "         grad_fn=<AddBackward0>),\n",
       "  tensor([[[-0.0464, -0.4629, -0.7319,  ..., -0.6891, -0.1323, -0.2640],\n",
       "           [ 0.1985, -0.7400, -0.2175,  ..., -0.9603, -0.1912,  0.3117],\n",
       "           [ 0.2049, -0.8075, -0.3407,  ..., -1.2391, -0.0761, -0.1112],\n",
       "           ...,\n",
       "           [-0.0433,  0.0173, -0.2959,  ..., -0.8226,  0.1612,  0.3133],\n",
       "           [ 0.0697, -0.4620, -0.6588,  ..., -1.0219, -0.2620, -0.0253],\n",
       "           [ 0.2448, -0.5580, -0.5395,  ..., -0.8058, -0.1088,  0.0271]]],\n",
       "         grad_fn=<AddBackward0>),\n",
       "  tensor([[[-0.3161, -0.3033, -1.3436,  ..., -0.9298,  0.0516, -0.8280],\n",
       "           [ 0.1519, -0.2383, -0.5411,  ..., -1.4893,  0.0775, -0.1455],\n",
       "           [ 0.0197, -0.4180, -0.7886,  ..., -1.3295,  0.2546, -0.4180],\n",
       "           ...,\n",
       "           [-0.2388, -0.1310, -0.3212,  ..., -1.0360,  0.3216,  0.6396],\n",
       "           [-0.0766, -0.0144, -0.8855,  ..., -1.5034,  0.1253, -0.4751],\n",
       "           [ 0.0317, -0.4651, -0.9114,  ..., -0.9161, -0.0095, -0.2488]]],\n",
       "         grad_fn=<AddBackward0>),\n",
       "  tensor([[[-0.8413, -1.1583, -1.7064,  ..., -0.2392,  0.1501, -0.8520],\n",
       "           [-0.0129, -0.8522, -0.2303,  ..., -0.5730,  0.0681, -0.8588],\n",
       "           [-0.0342, -0.6234, -0.5427,  ..., -0.6407,  0.2145, -0.6643],\n",
       "           ...,\n",
       "           [-0.7768, -0.8254, -0.5807,  ..., -0.5661,  0.6684,  0.2439],\n",
       "           [-0.3809, -0.4564, -1.1294,  ..., -0.6121,  0.6455, -0.6184],\n",
       "           [-0.3606, -1.3319, -1.3168,  ..., -0.1383, -0.0107, -0.6802]]],\n",
       "         grad_fn=<AddBackward0>),\n",
       "  tensor([[[-0.5448, -0.7356, -3.1843,  ...,  0.7112,  0.8474, -0.7636],\n",
       "           [-0.0965, -0.4317, -1.0508,  ..., -0.2582,  0.7900, -0.9799],\n",
       "           [-0.0901, -0.3272, -1.2873,  ..., -0.3715,  0.9788, -0.2104],\n",
       "           ...,\n",
       "           [-1.4361, -0.3212, -1.1462,  ..., -0.4214,  0.8905,  0.2119],\n",
       "           [-0.4454, -0.2895, -2.4229,  ...,  0.3227,  1.1695, -0.7841],\n",
       "           [-0.6148, -0.8856, -2.5272,  ...,  0.4593,  0.5756, -0.5627]]],\n",
       "         grad_fn=<AddBackward0>),\n",
       "  tensor([[[ 0.0549, -1.1707, -2.8880,  ...,  1.3513, -0.1492, -0.9159],\n",
       "           [ 0.6512, -0.8254, -0.5384,  ...,  0.2148,  0.2693, -1.0478],\n",
       "           [ 0.5826, -0.7059, -1.0225,  ..., -0.3880,  0.3715, -0.3533],\n",
       "           ...,\n",
       "           [-1.2204, -0.5051, -1.0442,  ..., -0.9238,  0.3824, -1.1015],\n",
       "           [ 0.2409, -0.6306, -2.3828,  ...,  0.8055,  0.6838, -1.3395],\n",
       "           [-0.3400, -1.3175, -2.1491,  ...,  1.0354, -0.0639, -0.7922]]],\n",
       "         grad_fn=<AddBackward0>),\n",
       "  tensor([[[-0.0235, -1.6726, -2.7324,  ...,  0.6596, -0.0363, -1.0370],\n",
       "           [ 0.8044, -1.2787, -0.3554,  ...,  0.3066,  0.3153, -1.2773],\n",
       "           [ 0.7223, -1.2403, -0.7575,  ..., -0.2552,  0.5198, -0.5616],\n",
       "           ...,\n",
       "           [-0.3952, -0.4564, -1.3144,  ..., -0.7332, -0.3444, -0.6579],\n",
       "           [ 0.4966, -1.0135, -2.3233,  ...,  0.4488,  0.9420, -1.5022],\n",
       "           [-0.2544, -1.6250, -1.9446,  ...,  0.4862, -0.0681, -1.0168]]],\n",
       "         grad_fn=<AddBackward0>)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "def forward_(model, inp):\n",
    "  inp = pre(inp)\n",
    "  print(inp.shape)\n",
    "\n",
    "  int_li = []\n",
    "  for b in model.blocks:\n",
    "    inp = b(inp)\n",
    "    print(inp.shape)\n",
    "    int_li.append(inp)\n",
    "\n",
    "  inp = post(inp)\n",
    "  print(inp.shape)\n",
    "  return inp, int_li\n",
    "\n",
    "forward_(model, inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.6628, -0.2821, -0.8683,  ...,  0.2226, -0.2399,  1.8106],\n",
      "         [-0.9508,  0.0593, -0.7059,  ...,  0.0527, -0.1204,  2.0101],\n",
      "         [-0.4276,  0.0181, -0.5251,  ...,  0.1864,  0.2215,  2.6931],\n",
      "         ...,\n",
      "         [-1.0209, -0.2023, -1.0002,  ...,  0.2080, -0.0751,  1.4898],\n",
      "         [-0.7854, -0.1687, -0.6663,  ...,  0.2828, -0.0201,  1.9001],\n",
      "         [-0.8792,  0.1097, -0.4218,  ...,  0.2727,  0.1519,  1.4047]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([[[0.1523, 0.1781, 0.0000,  ..., 0.2074, 0.1460, 0.4127],\n",
      "         [0.0000, 0.0000, 0.1363,  ..., 0.1633, 0.0000, 0.3089],\n",
      "         [0.0634, 0.0256, 0.0000,  ..., 0.2002, 0.0000, 0.3620],\n",
      "         ...,\n",
      "         [0.2519, 0.4729, 0.2573,  ..., 0.2046, 0.1547, 0.4366],\n",
      "         [0.1115, 0.2103, 0.2342,  ..., 0.0000, 0.0000, 0.1587],\n",
      "         [0.0582, 0.0910, 0.0000,  ..., 0.1158, 0.0843, 0.5832]]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(int_li[0])\n",
    "lin =torch.nn.Linear(768, 768, bias=False)\n",
    "rl = torch.nn.ReLU()\n",
    "out = rl(lin(int_li[0]))\n",
    "print(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 196\n",
    "inner_dim = 196//1\n",
    "group_queries = True\n",
    "group_key_values = True\n",
    "offset_groups = 4\n",
    "heads=1\n",
    "to_q = nn.Conv1d(dim, inner_dim, 1, groups = offset_groups if group_queries else 1, bias = False).to(device)\n",
    "to_k = nn.Conv1d(dim, inner_dim, 1, groups = offset_groups if group_key_values else 1, bias = False).to(device)\n",
    "to_v = nn.Conv1d(dim, inner_dim, 1, groups = offset_groups if group_key_values else 1, bias = False).to(device)\n",
    "to_out = nn.Conv1d(inner_dim, dim, 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'q' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/seongha/LT-ML/notebooks/attention.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B143.248.157.69/home/seongha/LT-ML/notebooks/attention.ipynb#ch0000010vscode-remote?line=0'>1</a>\u001b[0m group \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m t: rearrange(t, \u001b[39m'\u001b[39m\u001b[39mb (g d) n -> (b g) d n\u001b[39m\u001b[39m'\u001b[39m, g \u001b[39m=\u001b[39m offset_groups)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B143.248.157.69/home/seongha/LT-ML/notebooks/attention.ipynb#ch0000010vscode-remote?line=1'>2</a>\u001b[0m grouped_queries \u001b[39m=\u001b[39m group(q)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B143.248.157.69/home/seongha/LT-ML/notebooks/attention.ipynb#ch0000010vscode-remote?line=2'>3</a>\u001b[0m grouped_queries\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'q' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "group = lambda t: rearrange(t, 'b (g d) n -> (b g) d n', g = offset_groups)\n",
    "grouped_queries = group(q)\n",
    "grouped_queries.shape #torch.Size([4, 49, 768])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention( out, int_li, i=0):\n",
    "  \n",
    "  k, v = to_k(int_li[i]), to_v(int_li[i])\n",
    "  # k.shape, v.shape #(torch.Size([1, 196, 768]), torch.Size([1, 196, 768]))\n",
    "  q = to_q(out)\n",
    "  # q.shape #torch.Size([1, 196, 768])\n",
    "\n",
    "  # split out heads\n",
    "  q, k, v = map(lambda t: rearrange(t, 'b (h d) n -> b h n d', h = heads), (q, k, v))\n",
    "\n",
    "  # query / key similarity\n",
    "  sim = einsum('b h i d, b h j d -> b h i j', q, k)\n",
    "  # numerical stability\n",
    "\n",
    "  sim = sim - sim.amax(dim = -1, keepdim = True).detach()\n",
    "\n",
    "  # attention\n",
    "  dropout = nn.Dropout(0.0)\n",
    "  attn = sim.softmax(dim = -1)\n",
    "  attn = dropout(attn)\n",
    "  attn.shape\n",
    "\n",
    "  # aggregate and combine heads\n",
    "\n",
    "  out = einsum('b h i j, b h j d -> b h i d', attn, v)\n",
    "  out = rearrange(out, 'b h n d -> b (h d) n')\n",
    "  out = to_out(out)\n",
    "  print(out.shape)\n",
    "  return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dataset] Done!\n",
      "[annotation] Done!\n",
      "[json] Done!\n"
     ]
    }
   ],
   "source": [
    "train_dataset = COCO2017('../data/coco', phase='train')\n",
    "# partial=torch.utils.data.Subset(test_dataset, list(range(100)))\n",
    "# train_dataset = Voc2007Classification('data/voc', 'trainval', inp_name='data/voc/voc_glove_word2vec.pkl', LT=True)\n",
    "# test_dataset = Voc2007Classification('data/voc', 'test', inp_name='data/voc/voc_glove_word2vec.pkl')\n",
    "# train_dataset = COCO2014('data/coco', phase='train', inp_name='data/coco/coco_glove_word2vec.pkl')\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                  std=[0.229, 0.224, 0.225])\n",
    "train_dataset.transform = transforms.Compose([\n",
    "                Warp(224),\n",
    "                transforms.ToTensor(),\n",
    "                normalize,\n",
    "            ])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=50, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MultiLabelSoftMarginLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:07, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/seongha/LT-ML/notebooks/attention.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B143.248.157.69/home/seongha/LT-ML/notebooks/attention.ipynb#ch0000023vscode-remote?line=7'>8</a>\u001b[0m feat_Var \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mVariable(img)\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B143.248.157.69/home/seongha/LT-ML/notebooks/attention.ipynb#ch0000023vscode-remote?line=9'>10</a>\u001b[0m \u001b[39m# output = model(feat_Var, None).detach()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B143.248.157.69/home/seongha/LT-ML/notebooks/attention.ipynb#ch0000023vscode-remote?line=10'>11</a>\u001b[0m \u001b[39m# output = model(feat_Var)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B143.248.157.69/home/seongha/LT-ML/notebooks/attention.ipynb#ch0000023vscode-remote?line=11'>12</a>\u001b[0m output, int_li \u001b[39m=\u001b[39m forward_(model, feat_Var)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B143.248.157.69/home/seongha/LT-ML/notebooks/attention.ipynb#ch0000023vscode-remote?line=13'>14</a>\u001b[0m out \u001b[39m=\u001b[39m attention(output, int_li, i\u001b[39m%\u001b[39m\u001b[39m12\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B143.248.157.69/home/seongha/LT-ML/notebooks/attention.ipynb#ch0000023vscode-remote?line=14'>15</a>\u001b[0m out \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mmean(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;32m/home/seongha/LT-ML/notebooks/attention.ipynb Cell 3'\u001b[0m in \u001b[0;36mforward_\u001b[0;34m(model, inp)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B143.248.157.69/home/seongha/LT-ML/notebooks/attention.ipynb#ch0000002vscode-remote?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward_\u001b[39m(model, inp):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B143.248.157.69/home/seongha/LT-ML/notebooks/attention.ipynb#ch0000002vscode-remote?line=3'>4</a>\u001b[0m   inp \u001b[39m=\u001b[39m pre(inp)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B143.248.157.69/home/seongha/LT-ML/notebooks/attention.ipynb#ch0000002vscode-remote?line=4'>5</a>\u001b[0m   \u001b[39mprint\u001b[39m(inp\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B143.248.157.69/home/seongha/LT-ML/notebooks/attention.ipynb#ch0000002vscode-remote?line=6'>7</a>\u001b[0m   int_li \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/LTML/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1125'>1126</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1126'>1127</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1127'>1128</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1128'>1129</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1129'>1130</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1130'>1131</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1131'>1132</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/LTML/lib/python3.9/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/torch/nn/modules/container.py?line=136'>137</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    <a href='file:///home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/torch/nn/modules/container.py?line=137'>138</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> <a href='file:///home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/torch/nn/modules/container.py?line=138'>139</a>\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    <a href='file:///home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/torch/nn/modules/container.py?line=139'>140</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/LTML/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1125'>1126</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1126'>1127</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1127'>1128</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1128'>1129</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1129'>1130</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1130'>1131</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1131'>1132</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/LTML/lib/python3.9/site-packages/timm/models/layers/patch_embed.py:35\u001b[0m, in \u001b[0;36mPatchEmbed.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='file:///home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/timm/models/layers/patch_embed.py?line=32'>33</a>\u001b[0m _assert(H \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_size[\u001b[39m0\u001b[39m], \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInput image height (\u001b[39m\u001b[39m{\u001b[39;00mH\u001b[39m}\u001b[39;00m\u001b[39m) doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt match model (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_size[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m).\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='file:///home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/timm/models/layers/patch_embed.py?line=33'>34</a>\u001b[0m _assert(W \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_size[\u001b[39m1\u001b[39m], \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInput image width (\u001b[39m\u001b[39m{\u001b[39;00mW\u001b[39m}\u001b[39;00m\u001b[39m) doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt match model (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_size[\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m).\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='file:///home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/timm/models/layers/patch_embed.py?line=34'>35</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mproj(x)\n\u001b[1;32m     <a href='file:///home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/timm/models/layers/patch_embed.py?line=35'>36</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflatten:\n\u001b[1;32m     <a href='file:///home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/timm/models/layers/patch_embed.py?line=36'>37</a>\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mflatten(\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)  \u001b[39m# BCHW -> BNC\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/LTML/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1125'>1126</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1126'>1127</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1127'>1128</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1128'>1129</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1129'>1130</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1130'>1131</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1131'>1132</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/LTML/lib/python3.9/site-packages/torch/nn/modules/conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=455'>456</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=456'>457</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/anaconda3/envs/LTML/lib/python3.9/site-packages/torch/nn/modules/conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    <a href='file:///home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=448'>449</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    <a href='file:///home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=449'>450</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    <a href='file:///home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=450'>451</a>\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    <a href='file:///home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=451'>452</a>\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> <a href='file:///home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=452'>453</a>\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    <a href='file:///home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=453'>454</a>\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "\n",
    "# model = get_model(i).to(device)\n",
    "model = model.train()\n",
    "act_li = np.array([[]])\n",
    "for i, (input, target) in tqdm(enumerate(train_loader)):\n",
    "  img, path = input\n",
    "  target[target == 0] = 1\n",
    "  target[target == -1] = 0\n",
    "  feat_Var = torch.autograd.Variable(img).float().to(device)\n",
    "  \n",
    "  # output = model(feat_Var, None).detach()\n",
    "  # output = model(feat_Var)\n",
    "  output, int_li = forward_(model, feat_Var)\n",
    "  \n",
    "  out = attention(output, int_li, i%12)\n",
    "  out = out.mean(dim=1)\n",
    "  criterion(out, target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "60887706f19020ebdc58f2aefdb30076f5f51d5973d281c7596168e0afd68511"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('LTML': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
