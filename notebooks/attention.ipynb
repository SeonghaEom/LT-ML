{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import torchvision\n",
    "from voc import *\n",
    "from coco import *\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet152, resnet101, resnet18, resnet34, resnet50\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from config import seed_everything\n",
    "seed_everything(0)\n",
    "import timm\n",
    "\n",
    "# from models import *\n",
    "from backbones.config import config\n",
    "import pathlib\n",
    "from torch import nn, einsum\n",
    "from einops import rearrange, repeat\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seongha/anaconda3/envs/LTML/lib/python3.9/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646756402876/work/aten/src/ATen/native/TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "model = timm.create_model(config[\"swin\"], num_classes=80, pretrained=True).to(device)\n",
    "pre = torch.nn.Sequential(*[model.patch_embed,\n",
    "model.pos_drop])\n",
    "\n",
    "print(len(model.layers))\n",
    "post = torch.nn.Sequential(*[model.norm,\n",
    "# model.fc_norm,\n",
    "model.head])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 9216, 128])\n",
      "torch.Size([1, 2304, 256])\n",
      "torch.Size([1, 576, 512])\n",
      "torch.Size([1, 144, 1024])\n",
      "torch.Size([1, 144, 1024])\n",
      "torch.Size([1, 144, 1024])\n",
      "torch.Size([1, 144, 80])\n"
     ]
    }
   ],
   "source": [
    "inp = torch.randn(1, 3, 384, 384).to(device)\n",
    "\n",
    "ln = nn.LayerNorm(1024).to(device)\n",
    "def forward_(model, inp):\n",
    "  inp = pre(inp)\n",
    "  print(inp.shape)\n",
    "\n",
    "  int_li = []\n",
    "  for b in model.layers:\n",
    "    inp = b(inp)\n",
    "    print(inp.shape)\n",
    "    int_li.append(inp)\n",
    "\n",
    "  inp = ln(inp)\n",
    "  print(inp.shape)\n",
    "  inp = post(inp)\n",
    "  print(inp.shape)\n",
    "  return inp, int_li\n",
    "\n",
    "inp, int_li = forward_(model, inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll1 = nn.Linear(256, 512, bias=False).to(device)\n",
    "ll2 = nn.Linear(512, 512, bias=False).to(device)\n",
    "ll3 = nn.Linear(1024, 512, bias=False).to(device)\n",
    "ll4 = nn.Linear(1024, 512, bias=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 512])\n",
      "torch.Size([1, 768, 512])\n",
      "torch.Size([1, 1792, 512])\n",
      "torch.Size([1, 2816, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0298,  0.1247,  0.0175,  ...,  0.0078,  0.2329,  0.1131],\n",
       "         [-0.2860, -0.2478, -0.3225,  ..., -0.1234, -0.2641, -0.4852],\n",
       "         [ 0.0967,  0.0544,  0.1409,  ...,  0.2103,  0.0117, -0.0634],\n",
       "         ...,\n",
       "         [-1.1835, -1.2034, -0.1693,  ..., -0.3606, -0.7717,  1.1472],\n",
       "         [ 0.2611,  0.2219, -0.1271,  ..., -0.2409,  0.0870,  0.8960],\n",
       "         [-0.3123, -0.3760, -0.3634,  ..., -0.1361, -0.2379, -1.3295]]],\n",
       "       device='cuda:0', grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_kv(int_li):\n",
    "  softmax = nn.functional.gumbel_softmax\n",
    "  T = rearrange(int_li[0], 'b N D -> b D N')\n",
    "  # print(T.shape)\n",
    "  val= softmax(ll1(int_li[0]), dim=1)\n",
    "  # print(val.shape)\n",
    "  res = torch.matmul(T, val)\n",
    "  # res = rearrange(res, 'b D N -> b N D')\n",
    "  print(res.shape) #([1, 256, 1])\n",
    "\n",
    "  T = rearrange(int_li[1], 'b N D -> b D N')\n",
    "  # print(T.shape)\n",
    "  val= softmax(ll2(int_li[1]), dim=1)\n",
    "  # print(val.shape)\n",
    "  test = torch.matmul(T, val)\n",
    "  # test = rearrange(test, 'b D N -> b N D')\n",
    "  res = torch.concat((res, test), dim=1)\n",
    "  print(res.shape)\n",
    "\n",
    "  T = rearrange(int_li[2], 'b N D -> b D N')\n",
    "  # print(T.shape)\n",
    "  val= softmax(ll3(int_li[2]), dim=1)\n",
    "  # print(val.shape)\n",
    "  test = torch.matmul(T, val)\n",
    "  # test = rearrange(test, 'b D N -> b N D')\n",
    "  res = torch.concat((res, test), dim=1)\n",
    "  print(res.shape)\n",
    "\n",
    "  T = rearrange(int_li[3], 'b N D -> b D N')\n",
    "  # print(T.shape)\n",
    "  val= softmax(ll4(int_li[2]), dim=1)\n",
    "  # print(val.shape)\n",
    "  test = torch.matmul(T, val)\n",
    "  # test = rearrange(test, 'b D N -> b N D')\n",
    "  res = torch.concat((res, test), dim=1)\n",
    "  print(res.shape)\n",
    "\n",
    "  return res\n",
    "\n",
    "get_kv(int_li)\n",
    "# ll2 = nn.Linear(512, 1, bias=False).to(device)\n",
    "# softmax = nn.Softmax(dim=1)\n",
    "# val, ind = softmax(ll2(int_li[1])).sort(dim=1, descending=True)\n",
    "# ind[0,0:4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 2816\n",
    "inner_dim = 1024\n",
    "group_queries = True\n",
    "group_key_values = True\n",
    "offset_groups = 1\n",
    "heads=1\n",
    "to_q = nn.Conv1d(144, inner_dim, 1, groups = offset_groups if group_queries else 1, bias = False).to(device)\n",
    "to_k = nn.Conv1d(dim, inner_dim, 1, groups = offset_groups if group_key_values else 1, bias = False).to(device)\n",
    "to_v = nn.Conv1d(dim, inner_dim, 1, groups = offset_groups if group_key_values else 1, bias = False).to(device)\n",
    "to_out = nn.Conv1d(inner_dim, 144, 1).to(device)\n",
    "# to_q = nn.Linear(1024, inner_dim, bias = False).to(device) #144,1024\n",
    "# to_k = nn.Linear(dim, inner_dim,  bias = False).to(device)\n",
    "# to_v = nn.Linear(dim, inner_dim,bias = False).to(device)\n",
    "# to_out = nn.Linear(inner_dim, 144, 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 1])\n",
      "torch.Size([1, 768, 1])\n",
      "torch.Size([1, 1792, 1])\n",
      "torch.Size([1, 2816, 1])\n",
      "torch.Size([1, 144, 1024])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.3120,  1.3120,  1.3120,  ...,  1.3120,  1.3120,  1.3120],\n",
       "         [ 0.3124,  0.3124,  0.3124,  ...,  0.3124,  0.3124,  0.3124],\n",
       "         [-0.3545, -0.3545, -0.3545,  ..., -0.3545, -0.3545, -0.3545],\n",
       "         ...,\n",
       "         [-1.2075, -1.2075, -1.2075,  ..., -1.2075, -1.2075, -1.2075],\n",
       "         [ 0.4282,  0.4282,  0.4282,  ...,  0.4282,  0.4282,  0.4282],\n",
       "         [ 0.5603,  0.5603,  0.5603,  ...,  0.5603,  0.5603,  0.5603]]],\n",
       "       device='cuda:0', grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def attention( out, int_li):\n",
    "  kv = get_kv(int_li)\n",
    "  k, v = to_k(kv), to_v(kv)\n",
    "  q = to_q(out)\n",
    "  # q.shape #torch.Size([1, 196, 768])\n",
    "\n",
    "  # split out heads\n",
    "  q, k, v = map(lambda t: rearrange(t, 'b (h d) n -> b h n d', h = heads), (q, k, v))\n",
    "\n",
    "  # query / key similarity\n",
    "  sim = einsum('b h i d, b h j d -> b h i j', q, k)\n",
    "  # numerical stability\n",
    "\n",
    "  sim = sim - sim.amax(dim = -1, keepdim = True).detach()\n",
    "\n",
    "  # attention\n",
    "  dropout = nn.Dropout(0.0)\n",
    "  attn = sim.softmax(dim = -1)\n",
    "  attn = dropout(attn)\n",
    "  attn.shape\n",
    "\n",
    "  # aggregate and combine heads\n",
    "\n",
    "  out = einsum('b h i j, b h j d -> b h i d', attn, v)\n",
    "  out = rearrange(out, 'b h n d -> b (h d) n')\n",
    "  out = to_out(out)\n",
    "  print(out.shape)\n",
    "  return out\n",
    "attention(int_li[3], int_li)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = COCO2017('../data/coco', phase='train')\n",
    "# partial=torch.utils.data.Subset(test_dataset, list(range(100)))\n",
    "# train_dataset = Voc2007Classification('data/voc', 'trainval', inp_name='data/voc/voc_glove_word2vec.pkl', LT=True)\n",
    "# test_dataset = Voc2007Classification('data/voc', 'test', inp_name='data/voc/voc_glove_word2vec.pkl')\n",
    "# train_dataset = COCO2014('data/coco', phase='train', inp_name='data/coco/coco_glove_word2vec.pkl')\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                  std=[0.229, 0.224, 0.225])\n",
    "train_dataset.transform = transforms.Compose([\n",
    "                Warp(384),\n",
    "                transforms.ToTensor(),\n",
    "                normalize,\n",
    "            ])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=50, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MultiLabelSoftMarginLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model = get_model(i).to(device)\n",
    "model = model.train()\n",
    "act_li = np.array([[]])\n",
    "for i, (input, target) in tqdm(enumerate(train_loader)):\n",
    "  img, path = input\n",
    "  target[target == 0] = 1\n",
    "  target[target == -1] = 0\n",
    "  feat_Var = torch.autograd.Variable(img).float().to(device)\n",
    "  \n",
    "  # output = model(feat_Var, None).detach()\n",
    "  # output = model(feat_Var)\n",
    "  output, int_li = forward_(model, feat_Var)\n",
    "  \n",
    "  out = attention(output, int_li)\n",
    "  out = out.mean(dim=1)\n",
    "  criterion(out, target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "60887706f19020ebdc58f2aefdb30076f5f51d5973d281c7596168e0afd68511"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('LTML': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
