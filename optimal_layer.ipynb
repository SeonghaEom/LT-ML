{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seongha/anaconda3/envs/MGSSL/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import torchvision\n",
    "from voc import *\n",
    "from coco import *\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet152, resnet101, resnet18, resnet34, resnet50\n",
    "from tqdm import tqdm\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "\n",
    "avail_pretrained_models = timm.list_models(pretrained=True)\n",
    "m_names = ['vit_base_patch16_224']\n",
    "\n",
    "\n",
    "m_li = [resnet18(pretrained=True), resnet34(pretrained=True), resnet50(pretrained=True), resnet101(pretrained=True), resnet152(pretrained=True)]\n",
    "model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=0)\n",
    "model = timm.create_model('resnet10t', pretrained=True)\n",
    "model.reset_classifier(0)\n",
    "\n",
    "config = resolve_data_config({}, model=model)\n",
    "transform = create_transform(**config)\n",
    "\n",
    "m_li.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=0)\n",
    "model.reset_classifier(0)\n",
    "\n",
    "config = resolve_data_config({}, model=model)\n",
    "transform = create_transform(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ResNet' object has no attribute 'patch_embed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/seongha/LT-ML/optimal_layer.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B143.248.157.158/home/seongha/LT-ML/optimal_layer.ipynb#ch0000002vscode-remote?line=12'>13</a>\u001b[0m feat_extractors\u001b[39m=\u001b[39m[]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B143.248.157.158/home/seongha/LT-ML/optimal_layer.ipynb#ch0000002vscode-remote?line=13'>14</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m12\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B143.248.157.158/home/seongha/LT-ML/optimal_layer.ipynb#ch0000002vscode-remote?line=14'>15</a>\u001b[0m     vit \u001b[39m=\u001b[39m [model\u001b[39m.\u001b[39;49mpatch_embed,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B143.248.157.158/home/seongha/LT-ML/optimal_layer.ipynb#ch0000002vscode-remote?line=15'>16</a>\u001b[0m     model\u001b[39m.\u001b[39mpos_drop,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B143.248.157.158/home/seongha/LT-ML/optimal_layer.ipynb#ch0000002vscode-remote?line=16'>17</a>\u001b[0m     model\u001b[39m.\u001b[39mblocks[:i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B143.248.157.158/home/seongha/LT-ML/optimal_layer.ipynb#ch0000002vscode-remote?line=17'>18</a>\u001b[0m     model\u001b[39m.\u001b[39mnorm,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B143.248.157.158/home/seongha/LT-ML/optimal_layer.ipynb#ch0000002vscode-remote?line=18'>19</a>\u001b[0m     model\u001b[39m.\u001b[39mfc_norm,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B143.248.157.158/home/seongha/LT-ML/optimal_layer.ipynb#ch0000002vscode-remote?line=19'>20</a>\u001b[0m     model\u001b[39m.\u001b[39mhead]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B143.248.157.158/home/seongha/LT-ML/optimal_layer.ipynb#ch0000002vscode-remote?line=20'>21</a>\u001b[0m     feat_extractors\u001b[39m.\u001b[39mappend(torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mSequential(\u001b[39m*\u001b[39mvit))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B143.248.157.158/home/seongha/LT-ML/optimal_layer.ipynb#ch0000002vscode-remote?line=21'>22</a>\u001b[0m \u001b[39mprint\u001b[39m(feat_extractors)\n",
      "File \u001b[0;32m~/anaconda3/envs/MGSSL/lib/python3.9/site-packages/torch/nn/modules/module.py:1185\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   <a href='file:///home/seongha/anaconda3/envs/MGSSL/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1182'>1183</a>\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   <a href='file:///home/seongha/anaconda3/envs/MGSSL/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1183'>1184</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> <a href='file:///home/seongha/anaconda3/envs/MGSSL/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1184'>1185</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   <a href='file:///home/seongha/anaconda3/envs/MGSSL/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1185'>1186</a>\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ResNet' object has no attribute 'patch_embed'"
     ]
    }
   ],
   "source": [
    "def get_feat_extr_resnet(model):\n",
    "    feat_extractors = []\n",
    "    tmp = []\n",
    "    for name, module in model.named_children():\n",
    "        print(name)\n",
    "        if name=='layer1' or name=='layer2' or name=='layer3' or name=='layer4' or name=='global_pool':\n",
    "            feat_extractors.append(torch.nn.Sequential(*(tmp+[model.global_pool])))\n",
    "            tmp.append(module)\n",
    "        else:\n",
    "            tmp.append(module)\n",
    "    len(feat_extractors)\n",
    "    return feat_extractors\n",
    "feat_extractors=[]\n",
    "for i in range(12):\n",
    "    vit = [model.patch_embed,\n",
    "    model.pos_drop,\n",
    "    model.blocks[:i+1],\n",
    "    model.norm,\n",
    "    model.fc_norm,\n",
    "    model.head]\n",
    "    feat_extractors.append(torch.nn.Sequential(*vit))\n",
    "print(feat_extractors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dataset] Done!\n",
      "[annotation] Done!\n",
      "[json] Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# train_dataset = Voc2007Classification('data/voc', 'trainval', inp_name='data/voc/voc_glove_word2vec.pkl', LT=True)\n",
    "train_dataset = COCO2014('data/coco', phase='train', inp_name='data/coco/coco_glove_word2vec.pkl', LT=True)\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                  std=[0.229, 0.224, 0.225])\n",
    "train_dataset.transform = transforms.Compose([\n",
    "                MultiScaleCrop(224, scales=(1.0, 0.875, 0.75, 0.66, 0.5), max_distort=2),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                normalize,\n",
    "            ])\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                            batch_size=32, shuffle=False,\n",
    "                                            num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get feat representation from pretrained layers\n",
    "def get_Z(train_loader, g):\n",
    "  for i, (input, target) in tqdm(enumerate(train_loader)):\n",
    "    target[target == 0] = 1\n",
    "    target[target == -1] = 0\n",
    "\n",
    "    feat_Var = torch.autograd.Variable(input[0]).float().detach()\n",
    "    if i==0:\n",
    "      Z=g(feat_Var).detach().numpy()\n",
    "      labels = target\n",
    "    Z = np.concatenate((Z, g(feat_Var).detach().numpy()), axis=0)\n",
    "    labels = np.concatenate((labels, target), axis=0)\n",
    "  return Z, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate transferability score\n",
    "## Z: Feature from single forward pass of target sample (tensor)\n",
    "def get_transferability(Z, labels, class_num=[], eps=1e-4,):\n",
    "  n, d = Z.shape #1090, 1000\n",
    "  \n",
    "  # print(Z.shape, torch.t(Z).shape)\n",
    "  inp = torch.eye(d) + torch.matmul(torch.t(Z), Z) * 1/(n*eps)\n",
    "  first_term = 0.5 * torch.logdet(inp)\n",
    "  print(\"first term: \", first_term)\n",
    "  second_term = 0\n",
    "  total_instance = 0\n",
    "  for i, n_c in enumerate(class_num):\n",
    "    Z_c = Z[np.where(labels[:,i] == 1)]\n",
    "    # print(Z_c.shape[0])\n",
    "    total_instance += Z_c.shape[0]\n",
    "    second_term += n_c/(2*sum(class_num)) * torch.logdet(torch.eye(d) + 1/(n_c*eps) * torch.matmul(torch.t(Z_c), Z_c))\n",
    "  print(\"second_term: \", second_term)\n",
    "  # print(total_instance)\n",
    "\n",
    "  return first_term - second_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8155.0\n"
     ]
    }
   ],
   "source": [
    "## get class num list\n",
    "with open('./voc_class_num.json', 'r') as f:\n",
    "  voc_class_num = json.load(f)\n",
    "li = []\n",
    "for k, v in voc_class_num.items():\n",
    "  pos_cnt = v[\"1\"]\n",
    "  if \"0\" in v.keys():\n",
    "    pos_cnt += v[\"0\"]\n",
    "  li.append(pos_cnt)\n",
    "\n",
    "li = list(np.load('coco_class_num.npy'))\n",
    "print(sum(li))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34it [00:09,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1090, 196, 768])\n",
      "torch.Size([1090, 150528])\n",
      "tensor(-7.9398e-09)\n"
     ]
    }
   ],
   "source": [
    "for g in feat_extractors:\n",
    "  Z, labels = get_Z(train_loader, g)\n",
    "  Z = torch.as_tensor(Z)\n",
    "  print(Z.shape)\n",
    "  Z = torch.flatten(Z, start_dim=1)\n",
    "  print(Z.shape)\n",
    "  ## centralize Z\n",
    "  Z = Z - torch.mean(Z)\n",
    "  print(torch.mean(Z))\n",
    "\n",
    "  ##scale down to trace\n",
    "  Z = Z.reshape(Z.shape[0], Z.shape[1])\n",
    "  Z /= torch.sqrt(torch.trace(torch.matmul(Z,torch.t(Z))))\n",
    "\n",
    "  score = get_transferability(Z, labels, li)\n",
    "  print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1\n",
      "bn1\n",
      "act1\n",
      "maxpool\n",
      "layer1\n",
      "layer2\n",
      "layer3\n",
      "layer4\n",
      "global_pool\n",
      "fc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:07,  8.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1893, 64])\n",
      "torch.Size([1893, 64])\n",
      "tensor(-3.6021e-08)\n",
      "first term:  tensor(1.1719)\n",
      "second_term:  tensor(1.1424)\n",
      "tensor(0.0294)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:09,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1893, 64])\n",
      "torch.Size([1893, 64])\n",
      "tensor(-6.8012e-08)\n",
      "first term:  tensor(1.1828)\n",
      "second_term:  tensor(1.1533)\n",
      "tensor(0.0296)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:11,  5.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1893, 128])\n",
      "torch.Size([1893, 128])\n",
      "tensor(-5.1135e-08)\n",
      "first term:  tensor(1.5084)\n",
      "second_term:  tensor(1.4430)\n",
      "tensor(0.0654)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:11,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1893, 256])\n",
      "torch.Size([1893, 256])\n",
      "tensor(-5.8566e-09)\n",
      "first term:  tensor(1.8629)\n",
      "second_term:  tensor(1.7569)\n",
      "tensor(0.1059)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:18,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1893, 512])\n",
      "torch.Size([1893, 512])\n",
      "tensor(-1.7003e-08)\n",
      "first term:  tensor(2.5729)\n",
      "second_term:  tensor(2.5034)\n",
      "tensor(0.0695)\n"
     ]
    }
   ],
   "source": [
    "for model in m_li[-1:]:\n",
    "  feat_extractors = get_feat_extr_resnet(model)\n",
    "  for g in feat_extractors:\n",
    "    Z, labels = get_Z(train_loader, g)\n",
    "    Z = torch.as_tensor(Z)\n",
    "    print(Z.shape)\n",
    "    Z = torch.flatten(Z, start_dim=1)\n",
    "    print(Z.shape)\n",
    "    ## centralize Z\n",
    "    Z = Z - torch.mean(Z)\n",
    "    print(torch.mean(Z))\n",
    "\n",
    "    ##scale down to trace\n",
    "    Z = Z.reshape(Z.shape[0], Z.shape[1])\n",
    "    Z /= torch.sqrt(torch.trace(torch.matmul(Z,torch.t(Z))))\n",
    "\n",
    "    score = get_transferability(Z, labels, li)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "765b26ec2fc4c2066cf7ce8a0dde5a8255de29dd3973b3be957926608459ba30"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('MGSSL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
